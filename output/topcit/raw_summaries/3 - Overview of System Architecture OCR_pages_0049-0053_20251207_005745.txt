LEARNING GUIDE: Pages 49-53
Generated: 2025-12-07 00:57:45
PDF: 3 - Overview of System Architecture OCR

================================================================================
LEARNING GUIDE
================================================================================

Here is a simplified, easy-to-read learning guide based on the provided text:

---

## Operating System Concepts: A Learning Guide (Pages 49-53)

### 01. Threads: Essential Concepts

*   **Shared Memory:** In a multi-thread system, threads within the same process share the same memory space, allowing direct access to common data.
*   **Efficiency:**
    *   Thread creation and context switching are more economical (faster, less resource-intensive) than for processes.
*   **Parallelism:** Threads increase a process's ability to perform tasks concurrently, enabling better utilization of multiprocessor systems.

### 02. Process Synchronization and Deadlock

#### A) Concept of Process Synchronization

*   **Race Condition:** Occurs when two or more parallel processes simultaneously access and modify the same shared data, and the final result depends on the unpredictable order of execution.
*   **Purpose:** Process synchronization is necessary to protect shared data during a race condition, ensuring that only one process manipulates the data at a time.

#### B) Critical Section Problem

*   **Critical Section:** A segment of code within a process where shared data is accessed and modified.
*   **Mutual Exclusion:** The fundamental requirement for critical sections: only one process can execute its critical section at any given time.
*   **Process Code Structure:**
    *   `entry section`: Code requesting permission to enter the critical section.
    *   `critical section`: Code where shared data is manipulated.
    *   `exit section`: Code executed after leaving the critical section.
    *   `remainder section`: The rest of the process's code.
*   **Conditions for Solving Critical Section Problem:**
    1.  **Mutual Exclusion:** If one process is in its critical section, no other process can be.
    2.  **Progress:** If no process is in a critical section and some processes want to enter, only processes not in their remainder sections can participate in the decision of which will enter next, and this decision cannot be postponed indefinitely.
    3.  **Bounded Waiting:** There must be a limit on the number of times other processes are allowed to enter their critical sections after a process has made a request to enter its own critical section and before that request is granted.

#### C) Solving the Critical Section Problem

*   **Hardware Method (Limited):** Disabling interrupts during critical section execution. Not efficient or feasible in multiprocessor environments due to performance degradation.
*   **Semaphore:**
    *   **Definition:** A synchronization tool, an integer variable (`S`) accessible only through two atomic operations:
        *   **P (wait):** Decrements `S`. If `S` becomes negative, the process waits.
        *   **V (signal):** Increments `S`. If `S` is less than or equal to zero, a waiting process is unblocked.
    *   **Functionality:**
        *   A process performs a `P` operation before entering the critical section (sets to "wait").
        *   It performs a `V` operation after exiting the critical section (sets to "signal").
        *   Other processes check the semaphore value; if it's in a "wait" state, they are prevented from entering, ensuring exclusive access.

#### D) Deadlock Status

*   **Definition:** A situation in a multi-programming environment where multiple processes are blocked indefinitely, each waiting for a resource held by another blocked process.
*   **Consequences:** Programs cannot finish, and system resources remain tied up.
*   **Conditions Causing Deadlock (All four must be met for deadlock to occur):**
    1.  **Mutual Exclusion:** Resources are non-shareable; only one process can use a resource at a time.
    2.  **Hold & Wait:** A process holds at least one resource while waiting to acquire additional resources held by other processes.
    3.  **Non-preemption:** Resources cannot be forcibly taken from a process; they can only be released voluntarily by the process holding them after it has completed its task.
    4.  **Circular Wait:** A set of processes (P0, P1, ..., Pn) exists such that P0 is waiting for a resource held by P1, P1 is waiting for a resource held by P2, ..., Pn-1 is waiting for a resource held by Pn, and Pn is waiting for a resource held by P0.
*   **Ways to Solve Deadlock:**
    *   **Prevention:** Eliminate one or more of the four necessary conditions for deadlock before it can occur.
    *   **Avoidance:** Dynamically allocate resources to avoid entering a "safe state" where deadlock is possible. (Does not remove conditions, but avoids states).
    *   **Detection:** Allow deadlocks to occur, then detect them and identify the processes and resources involved.
    *   **Recovery:** Resolve detected deadlocks by restarting deadlocked processes or rolling them back to an earlier, safe state.

### 03. Memory Unit Management

#### A) Understanding Memory Unit Management

*   **CPU-Memory Interaction:** The CPU can only execute instructions and read data if they are present in memory.
*   **Purpose:** Managing memory effectively to allow multiple processes to reside and run concurrently, improving system utilization.
*   **Virtual Memory:** A technique that allows processes to execute even if they are not entirely loaded into physical memory. It enables programs larger than physical memory to run.

#### B) Memory Unit Management Techniques

##### 1. Memory Unit Allocation Techniques

*   Methods for assigning available main memory to processes requesting space.
*   **Types:**
    *   **First-fit:** Allocates the *first* available memory block encountered that is large enough to satisfy the request.
        *   **Pros:** Quick allocation decision.
        *   **Cons:** Can lead to increased external fragmentation.
    *   **Best-fit:** Allocates the *smallest* available memory block that is just large enough to satisfy the request.
        *   **Pros:** Tends to leave larger contiguous free spaces.
        *   **Cons:** Can create many small, unusable free spaces, leading to fragmentation.
    *   **Worst-fit:** Allocates the *largest* available memory block.
        *   **Pros:** Aims to leave a large remaining free space, potentially more useful than tiny fragments left by best-fit.
        *   **Cons:** Can also cause fragmentation by breaking up the largest free block.

##### 2. Fragmentation Problem

*   **Cause:** Repeated memory allocation and deallocation cycles leave unusable gaps.
*   **Types:**
    *   **External Fragmentation:** Total available memory is sufficient to satisfy a request, but it is not contiguous (scattered in small blocks). The allocation techniques (first-fit, best-fit, worst-fit) can cause this.
        *   *Example:* 64,500 bytes free, process requests 64,450 bytes. 50 bytes are left as a tiny, potentially unusable external fragment.
    *   **Internal Fragmentation:** Occurs when a process is allocated a fixed-size memory block that is slightly larger than it actually needs. The unused space *within* the allocated block.
        *   *Example:* Process needs 30,000 bytes but is allocated a 65,000-byte partition. 35,000 bytes inside that partition are unused.

##### 3. Solving the Fragmentation Problem

*   **Compaction Technique:**
    *   **Method:** Merges small, scattered available memory blocks into one larger contiguous block.
    *   **Purpose:** Primarily used to eliminate external fragmentation in variable-size partition systems.
    *   **Drawbacks:** Complex to implement and causes high overhead due to the time required to move memory contents. Not widely used.
*   **Coalescing Technique:**
    *   **Method:** Combines adjacent free (unused empty) memory spaces in the free list into a single, larger free space.
    *   **Purpose:** Prevents the proliferation of many small, unusable free spaces by creating larger, more useful ones.

---

================================================================================
ORIGINAL TEXT (First 5000 chars)
================================================================================

--- Page 49 ---
ESSENCE
+ The memory  occupied  by a process  can be shared, and another  thread can access the same memory  address  in a
multi-thread  system.
+ The cost of thread creation  and context  exchange  is more economical  than the process,
+ Threads  increase  the parallel attributes  of the process  and enable the utilization  of multiprocessors.
[Figure  20] Single Thread and Multi-thread
03 Process  Synchronization  and Deadlock
A) Concept  of process  synchronization
A race condition  refers to two or more parallel processes  simultaneously  accessing  and changing  the same data,
or the order of manipulating  the data affecting  the execution  result. In a race condition,  only one process  must be
protected  to manipulate  data, and process  synchronization  is necessary  for its protection.
B) Critical  section  problem
For process  synchronization,  each process  defines a critical section in a part of the code and performs  the task of
changing  the data that is shared with other critical section processes.  Two or more processes  that are mutually
exclusive  cannot run in the critical section at the same time. [Figure 21] shows the structure  of the critical and
remainder  sections.
do {
entry section
critical  section // Critical  section
exit section
remainder  section  // Remainder  section
} while (TRUE):
[Figure 21] Critical Section  Structure  in a Process  Code
48 TOPCIT  ESSENCE


--- Page 50 ---
Overview  of System Architecture )
The critical area problem is to establish  rules so that the processes  cooperate  with each other. Each process  must
request  permission  to enter, even if it enters its critical section.  The part of the code that implements  such a request
is called the entry section.  The exit section  is after the critical section,  and the rest of the code is collectively  called
the remainder  section.
Solving  the critical section  problem  requires  satisfying  the following  conditions:
+ Mutual exclusion:  If a process  runs in its critical section,  the other processes  cannot  run their own critical section.
+ Progress:  Only processes  that are not running  in the remainder  section  can enter a critical  section  without  a running
process.
+ Bounded  waiting:  After a process  makes a request  to enter its critical section,  the time allowed  for other processes
to enter the critical section  should be limited until the process  enters  the critical section.
C) Solving  the critical  section  problem
One of the ways to solve the critical section problem is to configure  the synchronization  hardware,  not to allow
the interruption of generation  while the shared data in the critical section is being changed.  However,  the hardware
method  is not feasible,  since it deteriorates  the system  efficiency  in a multiprocessor  environment.  Another  way is to
use a semaphore,  which is a synchronization  tool. The semaphore,'S’,  is an integer  variable,  and only the P operation
(wait) and V operation  (signal)  are enabled.  If one process  modifies  the semaphore  value, the other processes  cannot
modify the same semaphore  value at the same time. It works by setting  the semaphore  value to “wait” when a
process  enters the critical section and changing  the value to “signal” when the process  exits the critical section.
Another  process  checks  the semaphore  value and does not enter the critical section  if the value is in the “wait” state,
preventing  multiple  processes  from simultaneously  accessing  the shared data.
D) Deadlock  status
In a multi-programming  environment,  the processes  compete  with each other to use limited resources.  When a
process  requests  a resource,  it obtains  a “standby”  status if the resource  is not available.  There may be a case when
the status of a process  in “standby”  is never changed  because  the requested  resource  is allocated  to other standby
processes.  This state is called the deadlock.
The deadlocked  processes  cannot  finish the running  program,  and the system cannot start other tasks because  the
resource  is tied to other processes.  <Table 5> shows the conditions  that can cause deadlock.  They include mutual
exclusion,  hold & wait, non-preemption,  and circular  wait. The deadlock  occurs  when these four conditions  are met.
<Table 5) Conditions  Causing  Deadlock
Condition Description
Mutual  exclusion + The state in which only one process  can use the shared resource.
+ The state in which processes  are requesting  other resources  while occupying  the current
resource,Hold & wait
+ The state in which the resource  allocated  to each process  cannot  be forcibly  released  untilNon-preemption . A
its use is complete
+ The state in which the requests  for a resource  by different  processes  are continuously
Circular  wait
repeated.
M3 Overview  of System  Architecture  49


--- Page 51 ---
ESSENCE
<Table 6> shows  how to solve the deadlock  state.
Table 6) Ways to Solve Deadlock  ...
