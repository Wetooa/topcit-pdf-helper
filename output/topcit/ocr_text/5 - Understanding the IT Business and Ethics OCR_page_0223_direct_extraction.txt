Understanding  the IT Business  and Ethics )
1) Design and develop in @ Refuse bribery @® Employer and | @ Integrity, @  Principle  ofaccurately,  clearly, fairly, and © Fair assessment customer Credibilit fairness
faithfully  to the business © 3 ‘i I ‘t tment usto tability | @ Fai y Principle  oforder equitable treatmen accountability ‘airness equitableness
2) Conduct  the quality
certification  process  and
supply  Al (robot) to the
business  operator
3) Maintain  a sense of
‘bill @ Safety, .
responsibility  for the product  | @ Safety, health, health @ Fair use of
and provides  continuous welfare ean, materialswelfareupgrades
4) Prepare  a countermeasure © Safety, health, @ Safety,
Devel- against malfunction  and welfare health,
oloper provide  within the product welfare
5) Comply with global standard © enhance ieunderstanding  of :design and implementation @ Operational
F technology neas much as possible  and © Operational Conditions
share knowledge Persofa
Conditions
© Legal
compliance
@ Integrity @ Be discreet | © Property ® leenetee
6) fulfill universal  social @ Refuse bribery in public rights pertya. @ Contribute
responsibility © Nonmaleficence speech © Intellectual@ Cooperation © Cooperation Property to held ofexpertise
@ Eco-
friendliness
From the ethical point of view, the most fundamental  of the identity  of artificial intelligence  (robots)  and its relations
with humans,  is the Three Laws of Robotics  by Isaac Asimov.
The Three Laws of Robotics  is a set of principles  that regulate  the behavior  of robots, which must be observed  for
every robot and present  an ethical perspective  on the identity  and function  of artificial intelligence  robots and their
relationship  with humans.
Mr. Asimov  first introduced  the rules in his 1942 short science fiction story "Runaround”  and then came up with the
Three Laws of Robotics  in the 1950 collection  “I, Robot.”
The Three Laws of Robotics  is an “command”  that is put into an Al robot at the manufacturing  stage. It is not an
ethics that an Al developer  must follow, but a “moral code” that the Al itself to be developed  must have. The three
commands  or the three laws are as follows.
Asimov's  Three Laws of Robotics
+ First Law: A robot may not injure a human being or, through  inaction,  allow a human  being to come to harm
+ Second  Law: A robot must obey the orders given it by human  beings except  where such orders  would conflict  with the First
Law. (However,  the First law takes precedence  over the Second.)
+ Third Law: A robot must protect  its own existence  as long as such protection  does not conflict  with the First or Second  Law.
(However,  the First and Second  laws take precedence  over the Third.)
M5 Understanding  the IT Business  and Ethics 221
