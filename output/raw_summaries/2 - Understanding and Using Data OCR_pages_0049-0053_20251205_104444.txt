LEARNING GUIDE: Pages 49-53
Generated: 2025-12-05 10:44:44
PDF: 2 - Understanding and Using Data OCR

================================================================================
LEARNING GUIDE
================================================================================

Here is a simplified, easy-to-read learning guide extracted from the provided text.

---

## Data Modeling Learning Guide

### I. Introduction to Data Modeling

#### A. Recent Trends & Key Issues

*   **Traditional Data Models:** Simple entities and relationships.
*   **Extended Data Models:**
    *   Supplement traditional models.
    *   Incorporate strengths of **Object-Oriented Data Models**.
    *   Express inheritance as **Super-type** (general entity) and **Sub-type** (specific entity inheriting from super-type).
    *   Designate **Grouping Type** for entities with multiple attribute values.
    *   **Prevalence:** About 70% of projects use super-type/sub-type.
*   **Problem:** Despite data modeling, physical data models often lack clear standards.
*   **Need:** Acquire and apply concrete data modeling techniques.

#### B. Essential Data Modeling Techniques & Knowledge

To apply data modeling effectively, understand:

1.  **Normalization Rules:** Fully know and apply them – the foundation of database creation.
    *   *Note:* Do not assume normalized models are inherently slow for inquiries.
2.  **Denormalization Technology:** Apply with proper understanding for performance.
3.  **Data Independence:** Apply a user-independent **Conceptual Schema**.
4.  **Relationships:** Understand the meaning and effect of **Identifier Relationships** (part of primary key) and **Non-identifier Relationships** (not part of primary key).
5.  **Super-type & Sub-type Conversion:** Understand concepts and consider performance during conversion.
6.  **Complete Relationships:** Avoid creating data models with missing relationships.
7.  **History Data Modeling:** Model occurrence, change, and progress data, considering performance.
8.  **Primary Keys:** Consider performance and index characteristics when setting them.

#### C. Learning Objectives

By studying this guide, you will be able to:

1.  Explain the concept of data modeling.
2.  Design a database following data modeling procedures.
3.  Design entities, attributes, and identifiers based on business requirements.
4.  Design relationships based on business requirements.
5.  Explain and resolve the **Connection Trap** (a problem in relational databases where a join operation produces incorrect or confusing results).
6.  Express an **Entity Relationship Diagram (ERD)**.
7.  Convert **Object-Relational Mapping (ORM)** (a programming technique for converting data between incompatible type systems using object-oriented programming languages).
8.  Explain the **Extended ER type**.
9.  Explain **Data Integrity** (accuracy and consistency of data over its entire life-cycle).
10. Designate primary and foreign keys.

#### D. Keywords

*   Data modeling
*   Entity
*   Property (Attribute)
*   Relationship
*   Identifier
*   Connection trap
*   ERD (Entity Relationship Diagram)
*   Extended ER

### II. Practical Business Preview: Impact of Poor Data Modeling

*   **Complex Data Models (like a maze):**
    *   Lead to countless trials and errors.
    *   Don't consider business or physical characteristics.
    *   Result in unclear data paths, making it hard to get desired results.
    *   Cause multiple **Join Operations** (combining rows from two or more tables) which degrade performance.
*   **Unnecessarily Large Number of Entities:**
    *   Inefficient data processing (SQL reads multiple tables when one would suffice).
*   **Two Major Problems from Increased Data:**
    1.  **Data Duplication:** Leads to **Data Consistency** problems.
    2.  **Fall in SQL Response Speed:** Leads to **Performance Decline**.
*   **Solution:** Optimize data modeling to fundamentally resolve these issues. This optimization must be done efficiently when modeling is performed.

### III. Concept and Procedure of Data Modeling

#### A. What is Data Modeling?

*   **Definition:** The process of abstracting the real world to create a database.
*   **Modeling Characteristics:**
    *   **Abstraction:** Expresses the real world in a specific format.
    *   **Simplification:** Uses agreed protocols, limited notation, and language.
    *   **Clarification:** Removes ambiguity, accurately describes phenomena for universal understanding.

#### B. Data Modeling Procedure

1.  **Requirements Collection and Analysis:**
    *   **Purpose:** Remove ambiguity from business requirements.
    *   **Output:** Produces a required specification or job description.
2.  **Database Design:** Performed in the following order:
    *   **Conceptual Modeling**
    *   **Logical Modeling**
    *   **Physical Modeling**

#### C. Academic vs. Industry Understanding of Modeling Phases

| Feature                       | Academic Understanding                                     | Industry Understanding                                                                                              |
| :---------------------------- | :--------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------ |
| **ERD Production Time**       | Conceptual Modeling phase                                  | Logical Modeling phase                                                                                              |
| **Conceptual Modeling**       | ERD is produced. Identifies entities and relationships.    | More abstract than ERD; summarizes subject area, core entity, relationship, and attribute. Not often studied academically. |
| **Logical Modeling**          | Produces structural drawing of the table. Identifies PK/FK. Normalization performed. | Produces ERD. Normalization generally performed here.                                                              |
| **Main Notation**             | Chen type ERD                                              | Crow's Foot type ERD                                                                                                |
| **Relationship Attributes**   | Relationship itself can have properties.                   | Attributes are included in connected entities or identified as a separate relationship entity.                        |
| **Normalization Phase**       | Performed in the logical modeling phase.                   | Generally performed in logical modeling.                                                                            |
| **Denormalization Phase**     | Not mentioned explicitly as a phase.                       | Performed in physical modeling for performance improvement.                                                         |
| **Physical Modeling Process** | Creating tables suitable for an actual DBMS.               | Converting an ERD into a table structure.                                                                           |

#### D. Concept of Process Modeling

*   **Definition:** Analyzing tasks to find missing or unnecessary steps to meet system functions efficiently within a specified time.
*   **Purpose:** Develop a high-quality system by systematically classifying tasks and designing menus/programs.
*   **Benefit:** Helps arrange tasks systematically, identifying missing/unnecessary ones, which aids data model creation.
*   **Tool:** **Process Hierarchy Diagram** – subdivides tasks into function area, function, process, and unit process.

#### E. Concept of Correlation Modeling

*   **Definition:** Analyzing how processes affect data and which events influence them during information system development.
*   **Inputs:** Uses **entity types** (from data modeling) and **unit processes** (from process modeling).
*   **Tool:** **CRUD Matrix** (Create, Read, Update, Delete)
    *   **Purpose:** Verifies tasks against the data model and process model during the analysis phase.
    *   **Benefit:** Helps understand testing and task data exchange in future development.

---

================================================================================
ORIGINAL TEXT (First 5000 chars)
================================================================================

--- Page 49 ---
ESSENCE
>> Recent  trends and major issues
The data modeling  technique  represented  by individual  entities  and relationships  has been used widely. In
recent times, however,  there has been an increase  in practical business  techniques  that try to express  the
composition  or workflow  of a business  more elaborately  in terms of the data modeling  expression  method.
Among  these, the extended  data model supplements  the shortcomings  of the traditional  data model which
expresses  the composition  with simple entities  and relationships  only and has the strengths  of the object-
oriented  data model. This model expresses  the object-oriented  inheritance  structure as a super-type  and
a sub-type  of data modeling,  and designates  a grouping  type that has multiple  attribute  values in a single
entity. An analysis  of commonly  implemented  projects  showed  that about 70% of them use the super-type
and sub-type  method.  As a result, even though  data modeling  is deployed,  there are many cases in which
the physical  data model is created  without  a clear standard.  Therefore,  concrete  data modeling  techniques,
which developer  can understand  accurately  and apply to practical  business,  need to be acquired  and applied
in the field.
Actually,  if the following  knowledge  and techniques,  which are frequently  mentioned  in actual projects,  are
known or learned,  they can be applied usefully.
- It is essential  to fully know and apply the normalization  rules, which are the starting  point of creating  a
database.
- Do not casually  think that inquiry performance  is slow in normalized  models.
- Denormalization  technology  should be applied  based on a proper  understanding.
- Auser-independent  conceptual  schema should be applied to data modeling  from the viewpoint  of data
independence.
- The meaning  and effect of identifier  relationships  and non-identifier  relationships  should be understood
before applying  them.
- Conversion  should be performed  after understanding  the concepts  of super-type  and sub-type  and after
considering  performance.
- Do not create a data model with a missing  relationship.
- History  data modeling  (occurrence,  change,  progress)  in consideration  of performance  should be available.
- When setting  primary  keys, the performance  and index characteristics  should be considered.
48 TOPCIT  ESSENCE


--- Page 50 ---
Database )
> Learning  objectives
1. To be able to explain the concept  of data modeling.
2. To be able to design a database  according  to the data modeling  procedure.
3. To be able to design entities, attributes,  and identifiers  in data modeling  according  to the business
requirements.
. To be able to design relationships  in data modeling  according  to the business  requirements.
. To be able to explain and solve the problem  of the connection  trap.
. To be able to explain how to express  the Entity Relationship  Diagram  (ERD).4
5.
6. To be able to explain how to convert  object-relational  mapping  (ORM).
7
8. To be able to explain the extended  entity-relationship  (ER) type.
9. To be able to explain data integrity.
10. To be able to designate  primary  keys and foreign keys.
> Keywords
+ Data modeling,  entity, property,  relationship,  identifier,  connection  trap, ERD, extended  ER
M2 Database  49


--- Page 51 ---
ESSENCE
+ Preview  for practical  business
A data model that is as complex  as a maze can ruin a project.  A complex  maze, like the one shown below
left, means that countless  trials and errors will be required  to find a fast path. Such a data model does
not consider  business  characteristics  and physical  characteristics.  As a result, the model has to undergo
countless  trials and errors to obtain the desired  result because  the path to the data is not clear. Also, even
if the same number  of paths is passed,  join operations  are generated  by checking  additional  conditions
only, without  passing  through  the optimized  path. In the end, multiple  join operations  further  degrade
performance.
In addition,  if an entity is expressed  unnecessarily  in large numbers,  data are processed  inefficiently  because
an SQL statement  should read several tables, while the intended  result can be obtained  by reading  and
processing  data from one table alone.
Start
Fol
Lhy
—
If we check the data only, the two kinds of problems  that arise due to increased  data can be summarized
as follows:
- Increased  data — Data duplication  > Problems  occur in data consistency.
- Increased  data — Fall in SQL response  speed — Performance  declines.
These two problems  become  more important  as the number  of data grows, and can be solved by
optimizing  data modeling,  which is the ideal way to fundamentally  resolve the problem.  However,  data
modeling  cannot  be performed  at any time. Therefore,  when data modeling  is performed  again, it should be
optimized  for efficiently  processing  da...
